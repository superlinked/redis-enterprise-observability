= Redis Enterprise Developer Observability Playbook
:revnumber: 1.0
:docinfo1:

== Introduction

This guide is intended to provide monitoring guidance to DevOps and SREs who are responsible for operating
Redis Enterprise clusters either on premise or self-managed in the cloud.
It is not intended for use with Redis services hosted by either Redis Inc or various cloud vendors.
This data can be collected using the native Prometheus integration or Dynatrace or Datadog Redis Enterprise extensions.

== Monitoring Overview

== Core system resources

=== Memory

[cols="1,1,1"]
|===
| *Metric name* | *Definition* | *Unit*
| memory_usage_percent | Used memory / memory limit for database | Percentage
|===

Every Redis Enterprise database has a maximum configured memory limit to ensure isolation
in a multi-database cluster.

==== Thresholds

The appropriate memory threshold depends on how the application is using Redis.

===== Caching workloads

For applications using Redis solely as a cache, you can safely let the memory usage
reach 100% as long as you have an https://redis.io/blog/cache-eviction-strategies/[eviction policy] in place. This will ensure
that Redis can evict keys while continuing to accept new writes.

While your Redis database is using 100% of available memory, it's important to monitor
performance.

1. https://redis.io/docs/latest/operate/oss_and_stack/management/optimization/latency/[Latency]

Average latency should be at or below 1 ms.

2. https://redis.io/glossary/cache-miss/[Cache miss ratio]

100*bdb_read_hits/(bdb_read_hits+bdb_read_misses) < 50

Read hit ratio is below 50%. If you are not using redis in a caching scenario, please disable this check. You may need to tune the threshold to match your application performance criteria.


3. https://redis.io/docs/latest/develop/reference/eviction/[Evicted keys]

bdb_evicted_objects > 1

Keys are being evicted from your database. In some caching use scenarios this may be acceptable, so please disable this check if you meet such requirements.

===== Non-caching workloads

If no eviction policy is enabled, then Redis will stop accepting writes once memory reaches 100%.
Therefore, for non-caching workloads, we recommend that you configure an alert at 80% memory usage.
Once your database reaches this 80% threshold, you should closely review the rate of memory usage growth.

==== Troubleshooting

|===
|Issue |Possible causes

|Possible spike in activity
|Check both the Network Traffic and Operations Per Second metrics to determine if there is a corresponding increase

|Database sized incorrectly
|View the Memory Usage raw bytes over time to see if a usage pattern has changed

|Incorrect retention policies
|Check to see if keys are being Evicted or Expired
|===

==== Remediation

|===
|Action |Method

|Increase database memory
|Raise the database memory limit using the Redis Enterprise console or its API.

|Modify eviction policy
|For workloads that can tolerate evicted keys (e.g., caching), configure a global eviction policy for your database.

|Modify key retention policy
|Determine whether the application can set a reasonable TTL (time-to-live) on some or all
of the data written to Redis.

|===

=== CPU

[cols="1,1,1"]
|===
| *Metric name* | *Definition* | *Unit*
| Node CPU (User and System) | CPU time portion spent by user-space processes | Percentage (values falls between 0 and 1, inclusive, multiply by 100 to get percent)
| Proxy CPU | CPU time portion spent by user-space processes | Percentage (values falls between 0 and 1, inclusive, multiply by 100 to get percent)
| Shard CPU | CPU time portion spent by user-space processes | Percentage (values falls between 0 and 1, inclusive, multiply by 100 to get percent)

|===

To understand CPU metrics, it's worth recalling how a Redis Enterprise cluster is organized.
A cluster consists of one or more nodes. Each node is a VM (or cloud compute instance) or
a bare-metal server.

A database is a set of processes, known as shards, deployed across the nodes of a cluster.

In the dashboard, shard CPU is the CPU utilization of the processes that make up the database.
When diagnosing performance issues, start by looking at shard CPU.

==== Thresholds

Shard CPU, Proxy CPU, and Node CPU should remain below 80%.

==== Troubleshooting

There are many possible causes of high CPU utilization.

|===
|Issue| Possible causes

|Hot keys
|Inefficient Operations

|Hot Master Shard
|Inefficient usage

|High Proxy CPU
|Thundering herd of TLS connections
|===


==== Remediation

|===
|Action |Method

|Improve distribution |Increase number of shards

|Increase database memory
|Raise the database memory limit using the Redis Enterprise console or its API.

|Modify eviction policy
|For workloads that can tolerate evicted keys (e.g., caching), configure a global eviction policy for your database.

|Modify key retention policy
|Determine whether the application can set a reasonable TTL (time-to-live) on some or all
of the data written to Redis.
|===

=== Connections

Definition
redis_enterprise.conns (unit: count)
The count of current client connections to the database.

==== Monitoring notes
This metric should be monitored with both a minimum and maximum number of connections.  The minimum number of connections not being met is an excellent indicator of either networking or application configuration errors.  The maximum number of connections being exceeded may indicate a need to tune the database.
Possible Causes

|===
|Cause |Explanation| Actions

|Minimum clients not met| Incorrect client configuration, network firewall or network issues|Check client configurations and firewall settings
|Maximum connections exceeded|Client library is not releasing connections or an increase in the number of clients|Check client application configurations

|===

==== Troubleshooting

|===
|Issue| Possible causes

|No client connections
|Poorly configured client

|Too many connections
|Poorly configured client

|===


==== Remediation
|===
|Action |Method

|Clients Misconfigured
|Confirm client configurations

|Networking issue
|From a client node TELNET to the endpoint and issue the PING command

|Too many connections
|Be sure that you are using pooling on your client library and that your pools are sized according

|Too many connections
|Using rladmin run "tune proxy PROXY_NUMBER threads VALUE"

|===

== Performance measures

=== Latency

Definition
redis_enterprise.avg_latency (unit: microseconds)

This is the average amount of time that a request takes to return from the time that it first hits the Redis Enterprise proxy until the response is returned.  It does not include the full time from the remote clientâ€™s perspective.

==== Monitoring notes

Due to the fact that Redis is popular due to performance, generally you would expect most operations to return in single digit milliseconds.  Tune any alerts to match your SLA.  It is generally recommended that you also measure Redis operation latency at the client side to make it easier to determine if a server slow down or an increase in network latency is the culprit in any performance issues.

==== Troubleshooting

|===
|Issue| Possible causes

|Possible spike in requests
|Check both the Network Traffic and Operations Per Second metrics to determine if there is a corresponding increase

|Slow Running queries
|Check the slow log in the Redis Enterprise UI for the database

|Insufficient compute resources
|Check to see if the CPU Usage, Memory Usage Percentage, or Evictions are increasing
|===

==== Remediation
|===
|Action |Method

|Increase resources
|The database can be scaled up online by going to the Web UI and enabling clustering on the database.  In extreme cases more nodes can be added to the cluster and resources rebalanced.

|Inefficient Queries
|Redis allows you to view a slow log with a tunable threshold.  It can be viewed either in the Redis Enterprise UI or by running

redis-cli -h HOST -p PORT -a PASSWORD SLOWLOG GET 100
|===


=== Cache Hit Rate
Definition
redis_enterprise.cache_hit_rate (unit: percent)

This is the percentage of time that Redis is accessing a key that already exists.

==== Monitoring notes
This metric is useful only in the caching use case and should be ignored for all other use cases.  There are tradeoffs between the freshness of the data in the cache and efficacy of the cache mitigating traffic to any backend data service.  These tradeoffs should be considered carefully when determining the threshold for alerting.


==== Troubleshooting
This is highly specific to the application caching with no general rules that are applicable in the majority of cases.

|===
|Issue| Possible causes

|Low hit rate
|Data is being evicted due to TTL policy
|===


==== Remediation
Note that redis commands return information on whether or not a key or field already exists.  For example, HSET command returns the number of fields in the hash that were added.

|===
|Action |Method

|Monitor activity
|Check return values to determine if values were added
|===

=== Evictions
Definition
redis_enterprise.evicted_objects (unit: count)

This is the count of items that have been evicted from the database.


==== Monitoring notes
Eviction occurs when the database is close to capacity.  In this condition, the eviction policy starts to take effect.  While Expiration is fairly common in the caching use case, Eviction from the cache should generally be a matter of concern.  At very high throughput and very restricted resource use cases, sometimes the eviction sweeps cannot keep up with memory pressure.  Relying on Eviction as a memory management technique should be considered carefully.

==== Troubleshooting
While memory usage and network traffic will not help you pinpoint a root cause, network traffic is an excellent leading indicator of trouble.  Changes in network traffic patterns indicate corresponding changes in database behavior and further investigation is usually warranted.

|===
|Issue| Possible causes

|See Memory Usage Percentage Possible Causes
|===

==== Remediation
See Memory Usage Percentage Remediation

|===
|Action |Method

|===

See Memory Usage Percentage Remediation
Secondary Indicators
Network Traffic
redis_enterprise.ingress_bytes/redis_enterprise.egress_bytes (unit: bytes)
Counters for the network traffic coming into the database and out from the database

